{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emerging Technologies Project - Model creation and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this Jupyter Notebook, I will demonstrate how my model is made, as well how the model is trained using the MNIST dataset. \n",
    "\n",
    "#### Summary\n",
    "The model takes the images from the MNIST dataset and creates a model using the 70,000(60,000 training images, 10,000 test images) images supplied in the dataset which is then used to make a prediction on an image to make a prediction as to what that image is. This is done via building the model in layers and then training the model through epochs(iterating over the entire dataset = 1 epoch). The model then evaluates itself and is saved for use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    " - Keras: API which is uded to build the neural network\n",
    " - Keras.Layers: Part of Keras library which is used to create layers on the model\n",
    " - Numpy: Used for initialization of test and training images/labels (Conversion to numpy arrays)\n",
    " - Gzip: Used to uzip MNIST data set from files\n",
    " - Sklearn: Used to encode the categorical variables\n",
    " - Matplotlib: Used to plot results/diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras as kr\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import numpy as np\n",
    "import gzip\n",
    "import sklearn.preprocessing as pre\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the test and training images using GZIP\n",
    "Reading of the images is neccessary in order to train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../Web Application/MNIST Data Files/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    train_img = f.read()\n",
    "\n",
    "with gzip.open('../Web Application/MNIST Data Files/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    train_lbl = f.read()\n",
    "\n",
    "with gzip.open('../Web Application/MNIST Data Files/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    test_img = f.read()\n",
    "\n",
    "with gzip.open('../Web Application/MNIST Data Files/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    test_lbl = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "This is done in a sequentially (layer by layer) \n",
    "\n",
    "- Dense Layer: Means that each input neuron is connected to an output neuron - https://stackoverflow.com/a/56005761\n",
    "- 1000 Neurons(600 + 400) with input dimensions of 784 (28x28 - image size)\n",
    "- 10 Neuron layer to represent numbers 0-9\n",
    "#### Activation layers: https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/\n",
    " - Linear: Takes an input, multiplys by the weight of each neuron and creates an output which is proportional to input\n",
    " - Relu: All negative inputs or inputs which equal 0, results in faster training\n",
    " - Softmax: Normalizes the outputs for each class between 0 and 1, and divides by their sum,giving a probable value, sum, of all values must be equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a neural network, building it by layers.\n",
    "model = kr.models.Sequential()\n",
    "\n",
    "# Add a hidden layer with 1000 neurons and an input layer with 784.\n",
    "model.add(kr.layers.Dense(units=600, activation='linear', input_dim=784))\n",
    "model.add(kr.layers.Dense(units=400, activation='relu'))\n",
    "# Add a 10 neuron output layer.\n",
    "model.add(kr.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the model for training\n",
    " - Loss: categorical_crossentropy - used where only one result is correct in single label categorization - https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/categorical-crossentropy\n",
    "\n",
    "- Optimizer: Adam - Efficient Optimizer that is both reliable and quick to learn, performs best against other optimizers such as RMSProp, Adagrad etc... - https://medium.com/octavian-ai/which-optimizer-and-learning-rate-should-i-use-for-deep-learning-5acb418f9b2\n",
    "\n",
    "\n",
    "- Metrics: Accuracy - Used to test the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the graph.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
