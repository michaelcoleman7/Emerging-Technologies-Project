{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emerging Technologies Project - Model creation and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this Jupyter Notebook, I will demonstrate how my model is made, as well how the model is trained using the MNIST dataset. \n",
    "\n",
    "#### Summary\n",
    "The model takes the images from the MNIST dataset and creates a model using the 70,000(60,000 training images, 10,000 test images) images supplied in the dataset which is then used to make a prediction on an image to make a prediction as to what that image is. This is done via building the model in layers and then training the model through epochs(iterating over the entire dataset = 1 epoch). The model then evaluates itself and is saved for use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    " - Keras: API which is uded to build the neural network\n",
    " - Keras.Layers: Part of Keras library which is used to create layers on the model\n",
    " - Numpy: Used for initialization of test and training images/labels (Conversion to numpy arrays)\n",
    " - Gzip: Used to uzip MNIST data set from files\n",
    " - Sklearn: Used to encode the categorical variables\n",
    " - Matplotlib: Used to plot results/diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras as kr\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import numpy as np\n",
    "import gzip\n",
    "import sklearn.preprocessing as pre\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the test and training images using GZIP\n",
    "Reading of the images is neccessary in order to train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../Web Application/MNIST Data Files/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    train_img = f.read()\n",
    "\n",
    "with gzip.open('../Web Application/MNIST Data Files/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    train_lbl = f.read()\n",
    "\n",
    "with gzip.open('../Web Application/MNIST Data Files/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    test_img = f.read()\n",
    "\n",
    "with gzip.open('../Web Application/MNIST Data Files/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    test_lbl = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "This is done in a sequentially (layer by layer) \n",
    "\n",
    "- Dense Layer: Means that each input neuron is connected to an output neuron - https://stackoverflow.com/a/56005761\n",
    "- 1000 Neurons(600 + 400) with input dimensions of 784 (28x28 - image size)\n",
    "- 10 Neuron layer to represent numbers 0-9\n",
    "#### Activation layers: https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/\n",
    " - Linear: Takes an input, multiplys by the weight of each neuron and creates an output which is proportional to input\n",
    " - Relu: All negative inputs or inputs which equal 0, results in faster training\n",
    " - Softmax: Normalizes the outputs for each class between 0 and 1, and divides by their sum,giving a probable value, sum, of all values must be equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a neural network, building it by layers.\n",
    "model = kr.models.Sequential()\n",
    "\n",
    "# Add a hidden layer with 1000 neurons and an input layer with 784.\n",
    "model.add(kr.layers.Dense(units=600, activation='linear', input_dim=784))\n",
    "model.add(kr.layers.Dense(units=400, activation='relu'))\n",
    "# Add a 10 neuron output layer.\n",
    "model.add(kr.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the model for training\n",
    " - Loss: categorical_crossentropy - used where only one result is correct in single label categorization - https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/categorical-crossentropy\n",
    "\n",
    "- Optimizer: Adam - Efficient Optimizer that is both reliable and quick to learn, performs best against other optimizers such as RMSProp, Adagrad etc... - https://medium.com/octavian-ai/which-optimizer-and-learning-rate-should-i-use-for-deep-learning-5acb418f9b2\n",
    "\n",
    "\n",
    "- Metrics: Accuracy - Used to test the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the graph.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize training images and labels\n",
    "This is done by reshaping and resizing images into a numpy array, Also initialize the inputs for model by reshaping the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = ~np.array(list(train_img[16:])).reshape(60000, 28, 28).astype(np.uint8) / 255.0\n",
    "train_lbl =  np.array(list(train_lbl[ 8:])).astype(np.uint8)\n",
    "\n",
    "# Set up input value for training\n",
    "inputs = train_img.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up outputs\n",
    "This is done by using the sklearn package to encode the labels to binary for comparison later on when calculating model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up encoder and output values for training\n",
    "encoder = pre.LabelBinarizer()\n",
    "encoder.fit(train_lbl)\n",
    "outputs = encoder.transform(train_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    " - Epochs: refers to how many times the data set should be iterated over fully for training, found 10 to be a good amount with good results, (between 8-12 seems to be the best amount of epochs to choose from for the MNIST dataset)\n",
    " -  Batch Size: Refers to the number of samples per gradient update\n",
    " References to both of above: https://keras.io/models/model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Michael\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.5097 - accuracy: 0.84650s - loss: 0.5269 - \n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.2244 - accuracy: 0.9309\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.1796 - accuracy: 0.9449\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.1575 - accuracy: 0.9512\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.1369 - accuracy: 0.9582\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.1330 - accuracy: 0.9589\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.1212 - accuracy: 0.9630\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.1200 - accuracy: 0.9635\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.1084 - accuracy: 0.9659\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.1042 - accuracy: 0.9679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2447f920e80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(inputs, outputs, epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize test images and labels as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = ~np.array(list(test_img[16:])).reshape(10000, 784).astype(np.uint8) / 255.0\n",
    "test_lbl =  np.array(list(test_lbl[ 8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the amount of correct results\n",
    "This is done by comparing test images to the labels via the encoder\n",
    "- inverse_transform: Transform labels back to original encoding - https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "\n",
    "- model.predict: This is used to get the model to predict a result, returned in the form of an array - https://keras.io/models/model/\n",
    "\n",
    "Output: Below output is refering to the sum of the outputs from 10,000 test images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9496"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(encoder.inverse_transform(model.predict(test_img)) == test_lbl).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model accuracy\n",
    "Test the model using the inputs and outputs\n",
    "- Verbose: set to either 0 or 1, 0 = silent, 1 = progress bar - https://keras.io/models/model/\n",
    "Accuracy of model is displayed below as a percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 95.58%\n"
     ]
    }
   ],
   "source": [
    "# Test the model accuracy - https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "scores = model.evaluate(inputs, outputs, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model via an image\n",
    "- Test by printing a result of the prediction\n",
    "- Then plot the result using matplotlib to confirm that its correct\n",
    "- As you can see, the prediction is one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test image prediction is:\",model.predict(test_img[5:6]).argmax())\n",
    "\n",
    "plt.imshow(test_img[5].reshape(28, 28), cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
