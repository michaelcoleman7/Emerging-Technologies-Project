{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emerging Technologies Project - Model creation and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this Jupyter Notebook, I will demonstrate how my model is made, as well how the model is trained using the MNIST dataset. \n",
    "\n",
    "#### Summary\n",
    "The model takes the images from the MNIST dataset and creates a model using the 70,000(60,000 training images, 10,000 test images) images supplied in the dataset which is then used to make a prediction on an image to make a prediction as to what that image is. This is done via building the model in layers and then training the model through epochs(iterating over the entire dataset = 1 epoch). The model then evaluates itself and is saved for use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    " - Keras: API which is uded to build the neural network\n",
    " - Keras.Layers: Part of Keras library which is used to create layers on the model\n",
    " - Numpy: Used for initialization of test and training images/labels (Conversion to numpy arrays)\n",
    " - Gzip: Used to uzip MNIST data set from files\n",
    " - Sklearn: Used to encode the categorical variables\n",
    " - Matplotlib: Used to plot results/diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras as kr\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import numpy as np\n",
    "import gzip\n",
    "import sklearn.preprocessing as pre\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the test and training images using GZIP\n",
    "Reading of the images is neccessary in order to train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../Web Application/MNIST Data Files/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    train_img = f.read()\n",
    "\n",
    "with gzip.open('../Web Application/MNIST Data Files/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    train_lbl = f.read()\n",
    "\n",
    "with gzip.open('../Web Application/MNIST Data Files/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    test_img = f.read()\n",
    "\n",
    "with gzip.open('../Web Application/MNIST Data Files/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    test_lbl = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "This is done in a sequentially (layer by layer) \n",
    "\n",
    "- Dense Layer: Means that each input neuron is connected to an output neuron - https://stackoverflow.com/a/56005761\n",
    "- 1000 Neurons(600 + 400) with input dimensions of 784 (28x28 - image size)\n",
    "- 10 Neuron layer to represent numbers 0-9\n",
    "#### Activation layers: https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/\n",
    " - Linear: Takes an input, multiplys by the weight of each neuron and creates an output which is proportional to input\n",
    " - Relu: All negative inputs or inputs which equal 0, results in faster training\n",
    " - Softmax: Normalizes the outputs for each class between 0 and 1, and divides by their sum,giving a probable value, sum, of all values must be equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a neural network, building it by layers.\n",
    "model = kr.models.Sequential()\n",
    "\n",
    "# Add a hidden layer with 1000 neurons and an input layer with 784.\n",
    "model.add(kr.layers.Dense(units=600, activation='linear', input_dim=784))\n",
    "model.add(kr.layers.Dense(units=400, activation='relu'))\n",
    "# Add a 10 neuron output layer.\n",
    "model.add(kr.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the model for training\n",
    " - Loss: categorical_crossentropy - used where only one result is correct in single label categorization - https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/categorical-crossentropy\n",
    "\n",
    "- Optimizer: Adam - Efficient Optimizer that is both reliable and quick to learn, performs best against other optimizers such as RMSProp, Adagrad etc... - https://medium.com/octavian-ai/which-optimizer-and-learning-rate-should-i-use-for-deep-learning-5acb418f9b2\n",
    "\n",
    "\n",
    "- Metrics: Accuracy - Used to test the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the graph.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize training images and labels\n",
    "This is done by reshaping and resizing images into a numpy array, Also initialize the inputs for model by reshaping the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = ~np.array(list(train_img[16:])).reshape(60000, 28, 28).astype(np.uint8) / 255.0\n",
    "train_lbl =  np.array(list(train_lbl[ 8:])).astype(np.uint8)\n",
    "\n",
    "# Set up input value for training\n",
    "inputs = train_img.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up outputs\n",
    "This is done by using the sklearn package to encode the labels to binary for comparison later on when calculating model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up encoder and output values for training\n",
    "encoder = pre.LabelBinarizer()\n",
    "encoder.fit(train_lbl)\n",
    "outputs = encoder.transform(train_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    " - Epochs: refers to how many times the data set should be iterated over fully for training, found 10 to be a good amount with good results, (between 8-12 seems to be the best amount of epochs to choose from for the MNIST dataset)\n",
    " -  Batch Size: Refers to the number of samples per gradient update\n",
    " References to both of above: https://keras.io/models/model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Michael\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.5447 - accuracy: 0.8382\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.2552 - accuracy: 0.9214\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.1844 - accuracy: 0.9435\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1632 - accuracy: 0.9504\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1477 - accuracy: 0.9537\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1306 - accuracy: 0.9599\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1280 - accuracy: 0.9596\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1175 - accuracy: 0.9642\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1120 - accuracy: 0.9654\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.1050 - accuracy: 0.9674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2570030cf60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(inputs, outputs, epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize test images and labels as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = ~np.array(list(test_img[16:])).reshape(10000, 784).astype(np.uint8) / 255.0\n",
    "test_lbl =  np.array(list(test_lbl[ 8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the amount of correct results\n",
    "This is done by comparing test images to the labels via the encoder\n",
    "- inverse_transform: Transform labels back to original encoding - https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "\n",
    "- model.predict: This is used to get the model to predict a result, returned in the form of an array - https://keras.io/models/model/\n",
    "\n",
    "Output: Below output is refering to the sum of the outputs from 10,000 test images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9595"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(encoder.inverse_transform(model.predict(test_img)) == test_lbl).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model accuracy\n",
    "Test the model using the inputs and outputs\n",
    "- Verbose: set to either 0 or 1, 0 = silent, 1 = progress bar - https://keras.io/models/model/\n",
    "Accuracy of model is displayed below as a percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 96.83%\n"
     ]
    }
   ],
   "source": [
    "# Test the model accuracy - https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "scores = model.evaluate(inputs, outputs, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model via an image\n",
    "- Test by printing a result of the prediction\n",
    "- Then plot the result using matplotlib to confirm that its correct\n",
    "- As you can see, the prediction is 1 and printing out that image also results in 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image prediction is: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Test image prediction is:\",model.predict(test_img[5:6]).argmax())\n",
    "\n",
    "plt.imshow(test_img[5].reshape(28, 28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "This saves the model so that it can be loaded elsewhere, i.e can be used in flaskapp to predict the number drawn without making the user wait until the model is created for each prediction.\n",
    "- Save the entire model to a HDF5 file. - https://jovianlin.io/saving-loading-keras-models/\n",
    "- The '.h5' extension indicates that the model shuold be saved to HDF5.\n",
    "- Model is being saved to Web Application folder for use in Flask application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Web Application/model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
